{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists. This project evaluates the results of an A/B test run by an e-commerce website. The goal is to the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setting a seed to ensure replicability\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the `ab_data.csv` data and store it in `df`.\n",
    "Looking at the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the number of rows in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique users in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To check if any cleaning is required, we look at the number of times the `new_page` and `treatment` don't line up. The treatment group should have been presented the new page, while the control group should have used the old page. But we see that this isn't always the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group      landing_page\n",
       "control    new_page          1928\n",
       "           old_page        145274\n",
       "treatment  new_page        145311\n",
       "           old_page          1965\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['group', 'landing_page']).count().user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter =(\n",
    "    ((df.group == 'control') & (df.landing_page == 'new_page'))\n",
    "    |\n",
    "    ((df.group == 'treatment') & (df.landing_page == 'old_page'))\n",
    ")\n",
    "\n",
    "filter.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, checking for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         False\n",
       "timestamp       False\n",
       "group           False\n",
       "landing_page    False\n",
       "converted       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rows where **treatment** is not aligned with **new_page** or **control** is not aligned with **old_page**, we cannot be sure if this user received the new or old page. Given the small proportion of these entries, we can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(df[filter].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how many unique **user_id**s are in the new data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if there are any duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.duplicated('user_id').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the row information for the repeat **user_id**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_user_id = df2.user_id.value_counts().idxmax()\n",
    "df2[df2.user_id == dup_user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove **one** of the rows with a duplicate **user_id**, while keeping the same name for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df2.drop_duplicates(subset='user_id', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the cleaning step out of the way, we can start answering questions regarding the dataset.\n",
    "<br>First, to calculate the proportion of users converted (i.e. users who decide to pay for the company's product):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2.converted == 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the probability of an individual converting regardless of the page they receive.\n",
    "\n",
    "Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12038630450046119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_control = (\n",
    "    ((df2.group == 'control') & (df2.converted == 1))\n",
    "    .mean()\n",
    "    /\n",
    "    (df2.group == 'control').mean()\n",
    ")\n",
    "\n",
    "p_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_treatment = (\n",
    "    ((df2.group == 'treatment') & (df2.converted == 1))\n",
    "    .mean()\n",
    "    /\n",
    "    (df2.group == 'treatment').mean()\n",
    ")\n",
    "\n",
    "p_treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2.landing_page == 'new_page').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There seems to be evidence that, on average, users from the 'control' group (who see the old page) have a slightly higher probability of converting than the 'treatment' group (those who visit the new page). Further tests would be required to confirm reliability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Because of the time stamp associated with each event, one could technically run a hypothesis test continuously as each observation came in. However, then the hard question is whether to stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do we run in order to decide that neither page is better than another?\n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "For now, we will consider to make the decision based on all the data provided.  If we want to assume that the old page is better, unless the new page proves to be definitely better (at a Type I error rate of 5%), we can state our hypothesis in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null: **$p_{new}$** - **$p_{old}$** <= 0\n",
    "<br>Alternative: **$p_{new}$** - **$p_{old}$** > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assuming under the null hypothesis, that $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page, and that they are equal. We'll use a sample size for each page equal to the ones in **ab_data.csv**.  <br>\n",
    "\n",
    "We perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the **convert rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new = (df2.converted == 1).mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the **convert rate** for $p_{old}$ under the null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_old = (df2.converted == 1).mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is $n_{new}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new = (df2.landing_page == 'new_page').sum()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is $n_{old}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old = (df2.landing_page == 'old_page').sum()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null, and store these $n_{new}$ 1's and 0's in **new_page_converted**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_page_converted = np.random.choice([0,1],\n",
    "                                      size=n_new,\n",
    "                                      replace=True,\n",
    "                                      p=[1-p_new, p_new])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null, and store these $n_{old}$ 1's and 0's in **old_page_converted**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_page_converted = np.random.choice([0,1],\n",
    "                                      size=n_old,\n",
    "                                      replace=True,\n",
    "                                      p=[1-p_old, p_old])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding $p_{new}$ - $p_{old}$ for the simulated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0014334048761795448"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate 10,000 $p_{new}$ - $p_{old}$ values by repeating the process above, and store the values in **p_diffs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs = []\n",
    "for _ in range(10_000):\n",
    "    new_page_converted = np.random.choice([0,1],\n",
    "                                      size=n_new,\n",
    "                                      replace=True,\n",
    "                                      p=[1-p_new, p_new])\n",
    "    old_page_converted = np.random.choice([0,1],\n",
    "                                      size=n_old,\n",
    "                                      replace=True,\n",
    "                                      p=[1-p_old, p_old])\n",
    "    p_diffs.append(new_page_converted.mean() - old_page_converted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the **p_diffs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x20877127160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs);\n",
    "plt.axvline(p_treatment - p_control, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of the **p_diffs** are greater than the actual difference observed in our sample **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_diffs > (p_treatment - p_control)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This number represents the proportion of values in the null distribution that would be in favour of the alternative. Or in other words, the chance that a normal distribution based on the null hypothesis would *capture* a value that is equal to or greater than our sampling distribution statistic.\n",
    "In scientific studies this is known as the **p-value**. \n",
    "It is thus very likely that our observed difference came from the null, so given our Type I error threshold of 5%, we do not have sufficient evidence to reject the null. This means that users visiting the new page do not have a higher conversion rate when compared to the old page, and that this result is statistically significant.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative, we could also use a specialized library to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. \n",
    "\n",
    "Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17489, 17264, 145274, 145310)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = ((df2.landing_page == 'old_page') & (df2.converted == 1)).sum()\n",
    "convert_new = ((df2.landing_page == 'new_page') & (df2.converted == 1)).sum()\n",
    "n_old = (df2.landing_page == 'old_page').sum()\n",
    "n_new = (df2.landing_page == 'new_page').sum()\n",
    "\n",
    "convert_old, convert_new, n_old, n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using `stats.proportions_ztest` to compute the test statistic and p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest([convert_new, convert_old], [n_new, n_old], alternative='larger')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6448536269514729"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is our critical value at 95% confidence\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "norm.ppf(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we checked if the z-score exceeds the critical value of -1.64 in negative direction. Since our z-score of -1.31 does not exceed -1.64 in the negative, we fail to reject the null hypothesis. The conclusion therefore agrees with the one above, with the same statistical significance given by the p-value (0.906 and 0.905 respectively).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "In this final part, we will check that the result acheived in the previous A/B test can also be acheived by performing regression.<br>\n",
    "Since each row is either a conversion or no conversion, we'll use **logistic regression** to best predict one of the two alternatives.<br>\n",
    "The goal is to use `statsmodels` to fit the regression model, and check if there is a significant difference in conversion based on which page a customer receives.<br><br>\n",
    "First we need to create a colun for the intercept, and create a dummy variable column for the page each user received.<br>\n",
    "Adding an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['intercept'] = 1\n",
    "df2['ab_page'] = np.array(df2.group == 'treatment')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        0  \n",
       "1          1        0  \n",
       "2          1        1  \n",
       "3          1        1  \n",
       "4          1        0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model, and fit the model using the two columns created above to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df2.converted, df2[['intercept', 'ab_page']])\n",
    "result = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 06 Feb 2019</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:24:28</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Wed, 06 Feb 2019   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        12:24:28   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value from the logistic regression associated with 'ab_page' is 0.190. The difference from the p-value in the hypothesis testing could be explained by the following: \n",
    "<br>While in hypothesis testing we compared the difference in mean conversion rate for the two groups, with the null hypothesis being that the difference was less than or equal to zero, here we are comparing how well can being in one group or another determine the outcome of the dependent variable, with a null hypothesis being that the predicted conversion outcomes are no closer to the actual outcomes than we would expect by chance. <br><br>\n",
    "\n",
    "**How about considering other things that might influence whether or not an individual converts?**\n",
    "\n",
    "Adding additional factors in the regression would help us better understand how multiple variables might influence the response when considered together. However, the disadvantage would be the additional risks introduced by each additional variable, such as risks of non-liniarity, outliers or risk of coliniarity.\n",
    "\n",
    "Along with testing if the conversion rate changes for different pages, we can also look at which *country* a user lives in. For this, we will use the **countries.csv** dataset and merge together the two datasets on the approporiate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load countries dataframe\n",
    "countries_df = pd.read_csv('countries.csv')\n",
    "\n",
    "countries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290584, US    203619\n",
       " UK     72466\n",
       " CA     14499\n",
       " Name: country, dtype: int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check consistency\n",
    "countries_df.user_id.nunique(), countries_df.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  ab_page  CA  UK  \n",
       "user_id                                         \n",
       "834778           0          1        0   0   1  \n",
       "928468           0          1        1   0   0  \n",
       "822059           1          1        1   0   1  \n",
       "711597           0          1        0   0   1  \n",
       "710616           0          1        1   0   1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining on 'user_id' and save the new view\n",
    "joined_df = countries_df.set_index('user_id').join(df2.set_index('user_id'))\n",
    "\n",
    "# create dummy variables\n",
    "joined_df[['CA', 'UK']] = pd.get_dummies(joined_df.country)[['CA', 'UK']]\n",
    "\n",
    "joined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 06 Feb 2019</td> <th>  Pseudo R-squ.:     </th>  <td>1.521e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:24:31</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1984</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9967</td> <td>    0.007</td> <td> -292.314</td> <td> 0.000</td> <td>   -2.010</td> <td>   -1.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.518</td> <td> 0.129</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.746</td> <td> 0.456</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 06 Feb 2019   Pseudo R-squ.:               1.521e-05\n",
       "Time:                        12:24:31   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1984\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9967      0.007   -292.314      0.000      -2.010      -1.983\n",
       "CA            -0.0408      0.027     -1.518      0.129      -0.093       0.012\n",
       "UK             0.0099      0.013      0.746      0.456      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model to investigate impact of 'country'\n",
    "\n",
    "logit_mod = sm.Logit(joined_df.converted, joined_df[['intercept', 'CA', 'UK']])\n",
    "result = logit_mod.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9600211149716509, 1.0099491671175422)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponentiating each of the coefficients from the dummy variables will give us the multiplicative change in the odds:\n",
    "\n",
    "np.exp(-0.0408), np.exp(0.0099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0416437559600236"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the reciprocal for 'CA'\n",
    "1 / np.exp(-0.0408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High p-values suggest that the country variable do not seem to be significant in relation to the response variable ('converted').\n",
    "<br>The odds for a user to convert don't appear to change much based on their country. For any of the countries, all else being equal, there isn't much change in conversion when compared to the base ('US').**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at an interaction between page and country to see if there significant effects on conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 06 Feb 2019</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:24:33</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Wed, 06 Feb 2019   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        12:24:33   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "CA            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "UK             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod = sm.Logit(joined_df.converted, joined_df[['intercept', 'ab_page', 'CA', 'UK']])\n",
    "result = logit_mod.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9852104557227469, 0.9600211149716509, 1.0099491671175422)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.0149), np.exp(-0.0408), np.exp(0.0099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0150115583846535, 1.0416437559600236)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/ np.exp(-0.0149), 1/np.exp(-0.0408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result suggests that even when analized together, the page and the country do not make much difference in determining whether a user converts or not. Looking at the coefficients, we could however notice that, being from Canada (and landing on the new page) would make a user 1.04 less likely to convert then a user from US who lands on the new page.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
